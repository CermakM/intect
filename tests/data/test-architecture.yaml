name: null

optimizer: AdamOptimizer
batch_size: 10
learning_rate: 0.05

layers:
  - &conv16
    name: conv
    type: conv2d
    params:
      activation: relu
      filters: 16
      padding: SAME
      strides: [1, 1]
      kernel_size: [3, 3]
  - &pool
    name: pool
    type: max_pooling2d
    params:
      pool_size: [2, 2]
      strides: 1
#  - &conv32
#    name: conv
#    type: conv2d
#    params:
#      activation: relu
#      filters: 32
#      padding: SAME
#      strides: [1, 1]
#      kernel_size: [3, 3]
#  - *pool
  - &flat
    name: flat
    type: flatten
    params:
      null
  - &fcl128
    name: fcl
    type: dense
    params:
      activation: sigmoid
      units: 128
  -
    name: logits
    type: dense
    params:
      units: 5
