activation: [relu, relu, relu]
batch_size: 32
filter_shape:
  - [3, 3]
  - [3, 3]
filters: [6, 12]
input_shape: [32, 32, 3]
layers: [conv, conv, fcl]
learning_rate: 0.001
name: default
optimizer: AdamOptimizer
padding: SAME
stride: [1, 1, 1, 1]
